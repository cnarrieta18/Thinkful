Now it's time to flex your critical evaluation skills. Read the following descriptions of an experiment and its analysis, identify the flaws in each, and describe what you would do to correct them.

1. The Sith Lords are concerned that their recruiting slogan, "Give In to Your Anger," isn't very effective. Darth Vader develops an alternative slogan, "Together We Can Rule the Galaxy." They compare the slogans on two groups of 50 captured droids each. In one group, Emperor Palpatine delivers the "Anger" slogan. In the other, Darth Vader presents the "Together" slogan. 20 droids convert to the Dark Side after hearing Palpatine's slogan, while only 5 droids convert after hearing Vader's. The Sith's data scientist concludes that "Anger" is a more effective slogan and should continue to be used.
--Sample bias: the droids probably aren't representative of the whole galaxy population that the sith's want to convert; I would capture equivalent amount of humans, wookiees, hutts, and other species that sith's want to convert.  Context bias: the slogans are delivered by different speakers; I would have the slogans be delivered by just Vader to see if there is an actual increase with the original slogan versus the 5 from the new slogan.    

2. In the past, the Jedi have had difficulty with public relations. They send two envoys, Jar Jar Binks and Mace Windu, to four friendly and four unfriendly planets respectively, with the goal of promoting favorable feelings toward the Jedi. Upon their return, the envoys learn that Jar Jar was much more effective than Windu: Over 75% of the people surveyed said their attitudes had become more favorable after speaking with Jar Jar, while only 65% said their attitudes had become more favorable after speaking with Windu. This makes Windu angry, because he is sure that he had a better success rate than Jar Jar on every planet. The Jedi choose Jar Jar to be their representative in the future.
--Simpson's paradox: maybe Jar Jar spoke with more population from friendly planets driving up his overall percentage; I would look at the breakdown of percentages per planet.  

3. A company with work sites in five different countries has sent you data on employee satisfaction rates for workers in Human Resources and workers in Information Technology. Most HR workers are concentrated in three of the countries, while IT workers are equally distributed across worksites. The company requests a report on satisfaction for each job type. You calculate average job satisfaction for HR and for IT and present the report.
--First, make sure the key metric is not simply self reported and an actually measurable outcome.  Sample bias with HR: should the sample be representative of the small group outside the three countries; I may want to report the average satisfaction based on a sample only from the three countries, but include a side report of the outliers for business insight.  Assignment and contextual bias: the three countries with higher concentrations of HR workers may have different characteristics from the other two countries; I would make two reports on IT satisfaction with one for only the three countries and the second for all five countries.   

4. When people install the Happy Days Fitness Tracker app, they are asked to "opt in" to a data collection scheme where their level of physical activity data is automatically sent to the company for product research purposes. During your interview with the company, they tell you that the app is very effective because after installing the app, the data show that people's activity levels rise steadily.
--Sample bias: the group that opts in may be more concerned about their fitness levels.  Contextual bias: the group that opts in may feel additional pressure to send more active data. I would look at an opt out option or just tracking the times that the app are active and compare that to the activity data.  

5. To prevent cheating, a teacher writes three versions of a test. She stacks the three versions together, first all copies of Version A, then all copies of Version B, then all copies of Version C. As students arrive for the exam, each student takes a test. When grading the test, the teacher finds that students who took Version B scored higher than students who took either Version A or Version C. She concludes from this that Version B is easier, and discards it.
--Assignment and contextual bias: the versions of the test were not distributed randomly; also, the performance.  Hypothesis and key metric is not very clear: the teacher wants to prevent cheating and decides to drop the highest scoring test because it was assumed to be easier.  I would randomize the test based on assigned seating arrangement and checking for answer patterns of adjacent seats.  
